{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2JBLpFXsd4L"
      },
      "source": [
        "# IoT·인공지능·빅데이터 개론 및 실습 <br> 9/16 Logistic Regerssion & Neural Network with Scikit-Learn\n",
        "\n",
        "Adapted by Seonwoo Min from the \"An Introduction to Machine Learning with Scikit-learn\" tutorial (http://scikit-learn.org/stable/tutorial/basic/tutorial.html).\n",
        "\n",
        "In this excercise, we will cover:\n",
        "\n",
        "* Loading an example dataset & preprocessing\n",
        "* Logistic regression & neural network models in scikit-learn\n",
        "* Model training & prediction & evaluation\n",
        "* Model save & load\n",
        "* Homework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imrBlrfxsd4N"
      },
      "source": [
        "## 1. Loading an example dataset & preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-s_LWZtsd4O",
        "outputId": "44f135ef-7953-4a77-9c60-4ef130308dc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "data = load_digits()\n",
        "print(data.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trtt-95csd4P",
        "outputId": "f1cdc06c-42ee-40d8-e9a7-aa55c35ef1d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data:  (1797, 64)\n",
            "Label: (1797,)\n",
            "[0 1 2 3 4 5 6 7 8 9]\n",
            "0 178\n",
            "1 182\n",
            "2 177\n",
            "3 183\n",
            "4 181\n",
            "5 182\n",
            "6 181\n",
            "7 179\n",
            "8 174\n",
            "9 180\n"
          ]
        }
      ],
      "source": [
        "# Data shape & statistics\n",
        "print(\"Data: \", data['data'].shape)\n",
        "print(\"Label:\", data['target'].shape)\n",
        "\n",
        "# Print the number of samples for each class\n",
        "import numpy as np\n",
        "#################### To Do #################################\n",
        "print(np.unique(data['target']))\n",
        "for num in range(10):\n",
        "  print('%d %d' %(num, np.sum(data['target']==num)))\n",
        "############################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "0k5zdT63sd4P",
        "outputId": "ff60a293-d466-487b-c1b9-4e1a4ffbc33a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f442e58fc50>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#############################################################\n",
        "# Data Visaulization\n",
        "#############################################################\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "#################### To Do #################################\n",
        "plt.imshow(data['data'][272].reshape(8,8), cmap=plt.cm.gray_r)\n",
        "\n",
        "############################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjAxvbcxsd4P",
        "outputId": "7835b69e-64c2-4afd-c4bf-ac58b31ad101"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 64)\n",
            "(1597, 64)\n"
          ]
        }
      ],
      "source": [
        "#############################################################\n",
        "# 1st Preprocessing\n",
        "# Use the first 20 samples in each clss as test data\n",
        "# Use the others as training data\n",
        "#############################################################\n",
        "\n",
        "#################### To Do #################################\n",
        "test_data = []\n",
        "train_data = []\n",
        "test_target = []\n",
        "train_target = []\n",
        "N = len(data['data'])\n",
        "for c in range(10) :\n",
        "  is_in_this_class = data['target'] == c\n",
        "\n",
        "  data_in_this_class = data['data'][is_in_this_class]\n",
        "  target_in_this_class = data['target'][is_in_this_class]\n",
        "\n",
        "  test_data.append(data_in_this_class[:20])\n",
        "  train_data.append(data_in_this_class[20:])\n",
        "  test_target.append(target_in_this_class[:20])\n",
        "  train_target.append(target_in_this_class[20:])\n",
        "\n",
        "test_data = np.concatenate(test_data)\n",
        "train_data = np.concatenate(train_data)\n",
        "test_target = np.concatenate(test_target)\n",
        "train_target = np.concatenate(train_target)\n",
        "\n",
        "############################################################\n",
        "\n",
        "print(test_data.shape)\n",
        "print(train_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3nWrwAUsd4Q",
        "outputId": "c6441b92-f524-4ba6-fac6-176b5356d2ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40, 64)\n",
            "(320, 64)\n"
          ]
        }
      ],
      "source": [
        "#############################################################\n",
        "# 2nd Preprocessing\n",
        "# Let's use only 2 and 3 for binary classification\n",
        "#############################################################\n",
        "\n",
        "#################### To Do #################################\n",
        "\n",
        "\n",
        "test_data23 = []\n",
        "train_data23 = []\n",
        "test_target23 = []\n",
        "train_target23 = []\n",
        "N = len(data['data'])\n",
        "for c in [2,3] :\n",
        "  is_in_this_class = data['target'] == c\n",
        "  data_in_this_class = data['data'][is_in_this_class]\n",
        "  target_in_this_class = data['target'][is_in_this_class]\n",
        "\n",
        "  test_data23.append(data_in_this_class[:20])\n",
        "  train_data23.append(data_in_this_class[20:])\n",
        "  test_target23.append(target_in_this_class[:20])\n",
        "  train_target23.append(target_in_this_class[20:])\n",
        "\n",
        "test_data23 = np.concatenate(test_data23)\n",
        "train_data23 = np.concatenate(train_data23)\n",
        "test_target23 = np.concatenate(test_target23)\n",
        "train_target23 = np.concatenate(train_target23)\n",
        "############################################################\n",
        "\n",
        "print(test_data23.shape)\n",
        "print(train_data23.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erOmrhHMsd4Q"
      },
      "source": [
        "## 2. Logistic regression & neural network models in scikit-learn\n",
        "\n",
        "For full documentations refer to the following links: <br>\n",
        "Logistic Regression: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html <br>\n",
        "Neural network: http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0IqawNJnsd4Q"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "LR = LogisticRegression(max_iter=1000, solver='sag')\n",
        "NN = MLPClassifier(hidden_layer_sizes=(10), activation='relu', learning_rate_init=0.01, max_iter=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNFsqRSqsd4R"
      },
      "source": [
        "## 3. Model training & prediction & evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dyQOSkOsd4R",
        "outputId": "2491af18-5de9-4411-84fc-c64c07f1fbce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_target     : [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3]\n",
            "test_prediction : [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3]\n",
            "train_acc : 1.0\n",
            "test_acc  : 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "#############################################################\n",
        "# Logistic regression model\n",
        "#############################################################\n",
        "# Training\n",
        "LR = LogisticRegression(max_iter=2, solver='sag')\n",
        "LR.fit(train_data23, train_target23)\n",
        "\n",
        "# Prediction\n",
        "train_predict23 = LR.predict(train_data23)\n",
        "test_predict23 = LR.predict(test_data23)\n",
        "print(\"test_target     :\", test_target23)\n",
        "print(\"test_prediction :\", test_predict23)\n",
        "\n",
        "#################### To Do #################################\n",
        "train_prob23 = LR.predict_proba(train_data23)\n",
        "test_prob23 = LR.predict_proba(test_data23)\n",
        "acc_train = train_target23==train_predict23\n",
        "acc_test = test_target23==test_predict23\n",
        "train_acc23 = np.mean(acc_train)\n",
        "test_acc23 = np.mean(acc_test)\n",
        "############################################################\n",
        "#print(train_prob23)\n",
        "#print(test_prob23)\n",
        "print(\"train_acc :\", train_acc23)\n",
        "print(\"test_acc  :\", test_acc23)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0L6qxMBsd4R",
        "outputId": "ef7ccc39-5afe-429d-a4cb-70f6fa2ca2a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_target     : [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3]\n",
            "test_prediction : [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3\n",
            " 3 3 3]\n",
            "train_acc : 0.9875\n",
            "test_acc  : 0.975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "#############################################################\n",
        "# Neural network model\n",
        "#############################################################\n",
        "# Training\n",
        "NN = MLPClassifier(hidden_layer_sizes=(10), activation='relu', learning_rate_init=0.01, max_iter=10)\n",
        "NN.fit(train_data23, train_target23)\n",
        "\n",
        "# Prediction\n",
        "train_predict23 = NN.predict(train_data23)\n",
        "test_predict23 = NN.predict(test_data23)\n",
        "print(\"test_target     :\", test_target23)\n",
        "print(\"test_prediction :\", test_predict23)\n",
        "\n",
        "#################### To Do #################################\n",
        "train_prob23 = NN.predict_proba(train_data23)\n",
        "test_prob23 = NN.predict_proba(test_data23)\n",
        "acc_train = train_target23==train_predict23\n",
        "acc_test = test_target23==test_predict23\n",
        "train_acc23 = np.mean(acc_train)\n",
        "test_acc23 = np.mean(acc_test)\n",
        "############################################################\n",
        "#print(train_prob23)\n",
        "#print(test_prob23)\n",
        "print(\"train_acc :\", train_acc23)\n",
        "print(\"test_acc  :\", test_acc23)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-rJCkOOsd4R"
      },
      "source": [
        "## 4. Model save & load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fb-eQL2_sd4S"
      },
      "outputs": [],
      "source": [
        "# from sklearn.externals import joblib\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "if not os.path.exists('models'):\n",
        "    os.makedirs('models')\n",
        "    \n",
        "# save\n",
        "joblib.dump(NN, 'models/NN23.joblib') \n",
        "\n",
        "# load\n",
        "NN_load = joblib.load('models/NN23.joblib') \n",
        "\n",
        "#################### To Do #################################\n",
        "\n",
        "############################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYFh6IN7sd4S"
      },
      "source": [
        "## 5. Homework\n",
        "Now it's your job to experiment with models and achieve higher accuracy on the  **<font color=red>on the entire dataset</font>**. <br>\n",
        "Try different hyperparameter configurations and save the final model as \"final_model.joblib\" <br>\n",
        "Submit the current **notebook file and the saved final model** on ETL.\n",
        "* Maximum 10 points for >= 97% accuracy on the test set\n",
        "* Maximum 8 points for >= 96% accuracy on the test set\n",
        "* Maximum 6 points for >= 95% accuracy on the test set\n",
        "* Maximum 4 points for >= 94% accuracy on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "pHwxkZG4sd4S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6a8ea2a-6d35-418a-9048-00bc7b9c294c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['models/final_model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "#############################################################\n",
        "# Try different hyperparameters\n",
        "# Final model training\n",
        "#############################################################\n",
        "\n",
        "#################### To Do #################################\n",
        "'''\n",
        "for _ in range(6) :\n",
        "  for k in [100,1000] :\n",
        "    for i in [100,1000] :\n",
        "      for j in [0.001, 0.0005, 0.0015] :\n",
        "        NN = MLPClassifier(hidden_layer_sizes=(100,i), activation='relu', solver='adam', learning_rate_init=j, max_iter=1000)\n",
        "        NN.fit(train_data, train_target)\n",
        "\n",
        "        import joblib\n",
        "        import os\n",
        "\n",
        "        if not os.path.exists('models'):\n",
        "            os.makedirs('models')\n",
        "            \n",
        "        # save\n",
        "        joblib.dump(NN, 'models/NN_Homework.joblib') \n",
        "        # load\n",
        "        NN_load = joblib.load('models/NN_Homework.joblib')\n",
        "\n",
        "        # Prediction\n",
        "        train_predict = NN_load.predict(train_data)\n",
        "        test_predict = NN_load.predict(test_data)\n",
        "        #print(\"test_target     :\", test_target)\n",
        "        #print(\"test_prediction :\", test_predict)\n",
        "\n",
        "        # obtain test accuracy\n",
        "        acc_train = train_target==train_predict\n",
        "        acc_test = test_target==test_predict\n",
        "        train_acc = np.mean(acc_train)\n",
        "        test_acc = np.mean(acc_test)\n",
        "        print('Hidden Layer : (%d,%d)\\nLearning rate : %f'%(k,i,j))\n",
        "        print(\"train_acc :\", train_acc)\n",
        "        print(\"test_acc  :\", test_acc)\n",
        "        print(\"\")\n",
        "'''\n",
        "NN = MLPClassifier(hidden_layer_sizes=(1000,10000), activation='relu', solver = 'adam', learning_rate_init = 0.0005, max_iter = 1000)\n",
        "NN.fit(train_data, train_target)\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "if not os.path.exists('models'):\n",
        "    os.makedirs('models')\n",
        "    \n",
        "# save\n",
        "joblib.dump(NN, 'models/final_model.joblib') \n",
        "\n",
        "############################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "3LeBUMJ0sd4S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69981b5b-8779-4a57-f8af-738d0cc9b921"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_acc : 1.0\n",
            "test_acc  : 0.975\n"
          ]
        }
      ],
      "source": [
        "#############################################################\n",
        "# Final model test\n",
        "# Load the final model and obatin the test accuracy\n",
        "#############################################################\n",
        "\n",
        "#################### To Do #################################\n",
        "# load\n",
        "NN_load = joblib.load('models/final_model.joblib')\n",
        "\n",
        "# Prediction\n",
        "train_predict = NN_load.predict(train_data)\n",
        "test_predict = NN_load.predict(test_data)\n",
        "#print(\"test_target     :\", test_target)\n",
        "#print(\"test_prediction :\", test_predict)\n",
        "\n",
        "# obtain test accuracy\n",
        "acc_train = train_target==train_predict\n",
        "acc_test = test_target==test_predict\n",
        "train_acc = np.mean(acc_train)\n",
        "test_acc = np.mean(acc_test)\n",
        "\n",
        "print(\"train_acc :\", train_acc)\n",
        "print(\"test_acc  :\", test_acc)\n",
        "\n",
        "############################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyIBt2Pzsd4T"
      },
      "source": [
        "### Describe what you did here\n",
        "In this cell you should also write an explanation of what you did, any additional features that you implemented, and any visualizations or graphs that you make in the process of training and evaluating your model.\n",
        "* Maximum 10 points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-T_2FLxLsd4T"
      },
      "source": [
        "먼저, relu함수보다 tanh 함수의 classifying 능력이 더 뛰어나다는 모델의 적절한 은닝층 shape과 learning rate를 찾아봤다.\n",
        "\n",
        "# Test 1\n",
        "Hidden Layer : (100,100)\n",
        "Learning rate : 0.001000\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.94\n",
        "\n",
        "Hidden Layer : (100,100)\n",
        "Learning rate : 0.000500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.94\n",
        "\n",
        "Hidden Layer : (100,100)\n",
        "Learning rate : 0.001500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.945\n",
        "\n",
        "Hidden Layer : (100,1000)\n",
        "Learning rate : 0.001000\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.95\n",
        "\n",
        "Hidden Layer : (100,1000)\n",
        "Learning rate : 0.000500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.95\n",
        "\n",
        "Hidden Layer : (100,1000)\n",
        "Learning rate : 0.001500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.935\n",
        "\n",
        "Hidden Layer : (1000,100)\n",
        "Learning rate : 0.001000\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.95\n",
        "\n",
        "Hidden Layer : (1000,100)\n",
        "Learning rate : 0.000500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.95\n",
        "\n",
        "Hidden Layer : (1000,100)\n",
        "Learning rate : 0.001500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.945\n",
        "\n",
        "Hidden Layer : (1000,1000)\n",
        "Learning rate : 0.001000\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.935\n",
        "\n",
        "Hidden Layer : (1000,1000)\n",
        "Learning rate : 0.000500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.955\n",
        "\n",
        "Hidden Layer : (1000,1000)\n",
        "Learning rate : 0.001500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.95\n",
        "\n",
        "# Test 2\n",
        "\n",
        "Hidden Layer : (100,100)\n",
        "Learning rate : 0.001000\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.935\n",
        "\n",
        "Hidden Layer : (100,100)\n",
        "Learning rate : 0.000500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.955\n",
        "\n",
        "Hidden Layer : (100,100)\n",
        "Learning rate : 0.001500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.925\n",
        "\n",
        "Hidden Layer : (100,1000)\n",
        "Learning rate : 0.001000\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.92\n",
        "\n",
        "Hidden Layer : (100,1000)\n",
        "Learning rate : 0.000500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.95\n",
        "\n",
        "Hidden Layer : (100,1000)\n",
        "Learning rate : 0.001500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.95\n",
        "\n",
        "Hidden Layer : (1000,100)\n",
        "Learning rate : 0.001000\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.945\n",
        "\n",
        "Hidden Layer : (1000,100)\n",
        "Learning rate : 0.000500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.94\n",
        "\n",
        "Hidden Layer : (1000,100)\n",
        "Learning rate : 0.001500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.935\n",
        "\n",
        "Hidden Layer : (1000,1000)\n",
        "Learning rate : 0.001000\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.955\n",
        "\n",
        "Hidden Layer : (1000,1000)\n",
        "Learning rate : 0.000500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.97\n",
        "\n",
        "Hidden Layer : (1000,1000)\n",
        "Learning rate : 0.001500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.94\n",
        "\n",
        "# Test 3\n",
        "\n",
        "Hidden Layer : (100,100)\n",
        "Learning rate : 0.001000\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.965\n",
        "\n",
        "Hidden Layer : (100,100)\n",
        "Learning rate : 0.000500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.935\n",
        "\n",
        "Hidden Layer : (100,100)\n",
        "Learning rate : 0.001500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.95\n",
        "\n",
        "Hidden Layer : (100,1000)\n",
        "Learning rate : 0.001000\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.945\n",
        "\n",
        "Hidden Layer : (100,1000)\n",
        "Learning rate : 0.000500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.93\n",
        "\n",
        "Hidden Layer : (100,1000)\n",
        "Learning rate : 0.001500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.95\n",
        "\n",
        "Hidden Layer : (1000,100)\n",
        "Learning rate : 0.001000\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.95\n",
        "\n",
        "Hidden Layer : (1000,100)\n",
        "Learning rate : 0.000500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.945\n",
        "\n",
        "Hidden Layer : (1000,100)\n",
        "Learning rate : 0.001500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.93\n",
        "\n",
        "Hidden Layer : (1000,1000)\n",
        "Learning rate : 0.001000\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.93\n",
        "\n",
        "Hidden Layer : (1000,1000)\n",
        "Learning rate : 0.000500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.945\n",
        "\n",
        "Hidden Layer : (1000,1000)\n",
        "Learning rate : 0.001500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.93\n",
        "\n",
        "# Test 4\n",
        "\n",
        "Hidden Layer : (100,100)\n",
        "Learning rate : 0.001000\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.93\n",
        "\n",
        "Hidden Layer : (100,100)\n",
        "Learning rate : 0.000500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.925\n",
        "\n",
        "Hidden Layer : (100,100)\n",
        "Learning rate : 0.001500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.945\n",
        "\n",
        "Hidden Layer : (100,1000)\n",
        "Learning rate : 0.001000\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.945\n",
        "\n",
        "Hidden Layer : (100,1000)\n",
        "Learning rate : 0.000500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.975\n",
        "\n",
        "Hidden Layer : (100,1000)\n",
        "Learning rate : 0.001500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.945\n",
        "\n",
        "Hidden Layer : (1000,100)\n",
        "Learning rate : 0.001000\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.935\n",
        "\n",
        "Hidden Layer : (1000,100)\n",
        "Learning rate : 0.000500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.92\n",
        "\n",
        "Hidden Layer : (1000,100)\n",
        "Learning rate : 0.001500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.945\n",
        "\n",
        "Hidden Layer : (1000,1000)\n",
        "Learning rate : 0.001000\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.945\n",
        "\n",
        "Hidden Layer : (1000,1000)\n",
        "Learning rate : 0.000500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.96\n",
        "\n",
        "Hidden Layer : (1000,1000)\n",
        "Learning rate : 0.001500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.945\n",
        "\n",
        "# Test 5\n",
        "\n",
        "Hidden Layer : (100,100)\n",
        "Learning rate : 0.001000\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.94\n",
        "\n",
        "Hidden Layer : (100,100)\n",
        "Learning rate : 0.000500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.935\n",
        "\n",
        "Hidden Layer : (100,100)\n",
        "Learning rate : 0.001500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.925\n",
        "\n",
        "Hidden Layer : (100,1000)\n",
        "Learning rate : 0.001000\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.945\n",
        "\n",
        "Hidden Layer : (100,1000)\n",
        "Learning rate : 0.000500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.94\n",
        "\n",
        "Hidden Layer : (100,1000)\n",
        "Learning rate : 0.001500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.955\n",
        "\n",
        "Hidden Layer : (1000,100)\n",
        "Learning rate : 0.001000\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.92\n",
        "\n",
        "Hidden Layer : (1000,100)\n",
        "Learning rate : 0.000500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.955\n",
        "\n",
        "Hidden Layer : (1000,100)\n",
        "Learning rate : 0.001500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.925\n",
        "\n",
        "Hidden Layer : (1000,1000)\n",
        "Learning rate : 0.001000\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.945\n",
        "\n",
        "Hidden Layer : (1000,1000)\n",
        "Learning rate : 0.000500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.94\n",
        "\n",
        "Hidden Layer : (1000,1000)\n",
        "Learning rate : 0.001500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.96\n",
        "\n",
        "# Test 6\n",
        "\n",
        "Hidden Layer : (100,100)\n",
        "Learning rate : 0.001000\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.93\n",
        "\n",
        "Hidden Layer : (100,100)\n",
        "Learning rate : 0.000500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.925\n",
        "\n",
        "Hidden Layer : (100,100)\n",
        "Learning rate : 0.001500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.93\n",
        "\n",
        "Hidden Layer : (100,1000)\n",
        "Learning rate : 0.001000\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.96\n",
        "\n",
        "Hidden Layer : (100,1000)\n",
        "Learning rate : 0.000500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.94\n",
        "\n",
        "Hidden Layer : (100,1000)\n",
        "Learning rate : 0.001500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.96\n",
        "\n",
        "Hidden Layer : (1000,100)\n",
        "Learning rate : 0.001000\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.925\n",
        "\n",
        "Hidden Layer : (1000,100)\n",
        "Learning rate : 0.000500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.93\n",
        "\n",
        "Hidden Layer : (1000,100)\n",
        "Learning rate : 0.001500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.945\n",
        "\n",
        "Hidden Layer : (1000,1000)\n",
        "Learning rate : 0.001000\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.935\n",
        "\n",
        "Hidden Layer : (1000,1000)\n",
        "Learning rate : 0.000500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.925\n",
        "\n",
        "Hidden Layer : (1000,1000)\n",
        "Learning rate : 0.001500\n",
        "train_acc : 1.0\n",
        "test_acc  : 0.955<br>\n",
        "\n",
        "\n",
        "\n",
        "위와 같이 총 6번의 test를 진행 후에, 한번이라도 0.97 이상의 accuracy를 보인 (100,1000)과 (1000,1000)의 Shape, 그리고 0.0005의 learning rate 중에서, 평균적으로 더 높은 accuracy를 보인 (1000,1000)의 shape을 채택했다. <br>\n",
        "그러나 이후 몇번의 반복되는 accuracy 측정에서도,<br> \n",
        "accuracy가 각각 0.925, 0.95, 0.975, 0.95, 0.95로 정확도 평균이 0.95쯤 밖에 되지 않았다.<br>\n",
        "각각 1000개의 뉴런을 가지는 레이어의 수를 다섯개까지도 늘려봤으나 <br>\n",
        "레이어수 3개 : 0.90, 0.92, 0.95<br>\n",
        "레이어수 4개 : 0.935, 0.95, 0.94<br>\n",
        "레이어수 5개 : 0.94, 0.92, 0.94<br>\n",
        "위와 같이 정확도가 늘어나지 않아서,<br>\n",
        "은닉층의 두번쨰 레이어의 뉴런 수를 10000으로 크게 늘려봤다.<br>\n",
        "그랬더니 총 4번의 test에서 0.975, 0.95, 0.97, 0.975의  높은 정확도를 가지게 되어서, 이를 final model로 정했다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "he5Zfzj07f5u"
      },
      "execution_count": 34,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}